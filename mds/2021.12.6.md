# A Survey on Dialogue Summarization: Recent Advances and New Frontiers
arXiv:2107.03175v1
## Overview
Summarization: to **condense** into a **short summary** of a longer text.
2 paradigms: Extractive, Abstractive
Extractive: 选取vital sentence
Abstractive: 生成novel words
backbone：seq2seq结合attention

### Eval
F1 scores for ROUGE-1, ROUGE-2, and ROUGE-L
也有新的Metrics，e.g.BERTScore, MoverScore

## 分类
### Meeting
先前工作：**focus on** extractive meeting Summarization(2008-09)
但是信息分散不连贯(**scattered and incoherent**)
17年有人提出Abstractive的方法，dependency graph, graph-based
字面意思不够->因为interactive signals存在
比较tricky的：
使用辅助信息的(dialogue discourse, dialogue acts, domain terminologies)
能自动分段的：hierarchical adaptive segmental encoder-decoder network
从token-level到turn-level(??):hierarchical architectures

滑动窗口处理较长的会议的：https://aclanthology.org/2021.naacl-srw.10/

后面也提到了非语言的，像是“视觉焦点”(Visual Focus Of Attention)什么的，这些感觉不大需要细究

Benchmark：用pyrouge package，在Table2中

Highlight：长序列 多模态


### ⭐️Chat
First step：a multi-view summarizer combing both topic segments and conversational stages. 
- [ ] https://arxiv.org/abs/2010.01672

对interaction进行处理：
utilize fine-grained topic words as bridges between utterances to construct a topicword guided dialogue graph.
- [ ] https://openreview.net/forum?id=uFk038O5wZ
inter-utterance dialogue discourse structure && intrautterance action triples
- [x] arXiv:2104.08400 [cs]

由于**多参与者**和coreferences(就是多个名字表明同一个人)的问题很普遍:
模型生成的对话摘要总是存在事实不一致的问题(文章是指标、评估框架)
- [ ] https://arxiv.org/abs/2010.12834v2

强调通过说话者意识的自我关注机制
- [ ] https://ieeexplore.ieee.org/abstract/document/9414547

处理coreferences：
- [ ] https://arxiv.org/abs/2106.08556

无监督的 DialoGPT annotator，能做三种annotation任务：keywords extraction, redundancy detection and topic segmentation.
- [ ] https://arxiv.org/abs/2105.12544

摘要中也提到了SAMSum能用于其它的研究方向，比如对话生成，以及英语对话转化为印地语-英语对话并学习聊天摘要的问题Orz.





