# CTRLSUM: TOWARDS GENERIC CONTROLLABLE TEXT SUMMARIZATION(2012.04281)
训练时利用一些Keywords作为aditional input
3个数据集：CNN/Dailymail news articles,arXiv , and BIGPATENT patent documents
5个量化evaluate的方面：1）以实体为中心和（2）长度可控的摘要，（3）科学论文的贡献摘要，（4）专利摘要，以及（5）在零样本阅读理解设置中总结给定问题的答案。 

要点是，需要获取关键字，然后把它们作为附加输入。
## 提取Keywords
最大化ROUGE分数的摘要句子->找到和ground-truth中匹配的最长子序列->去重、stop words
Inference中，作为sequence labeling task，训练一个BERT-based sequence tagger，每个句子能得到一个selection probablity，找到最高的几个句子

## Training Details
将关键词添加到文档中，用special token分开，同时有dropout，防止学习时过于依赖关键词


## Inference With Keywords
### Entity Control
生成相关实体的摘要
### Length Control
先根据摘要长度进行分类，分为5个buckets，每个bucket有不同个数的关键词，计算一下平均的个数
test时，由用户指定0-4间的一个数l，在sequence tagger产生的selection probablity中，选出$K_l$个最高的句子

## PROMPTS
后面的三个方法是针对这些特定的input的，问题引导摘要，科学文献贡献摘要，专利摘要

# Towards User-Centric Text-to-Text Generation: A Survey
主要讲述的是NLG中的工作和挑战，多个学科都在推动这个领域

## User-Centric NLG
NLG包含广泛的任务，例如翻译、文本摘要、文本简化、等好多

### When是User-Centric
- 输出y是由有关u的信息$I_u$决定，换句话说，利用信息$I_u$来改变输入x到输出空间的投影。


# GSum: A General Framework for Guided Neural Abstractive Summarization
也是一种External Guidance
extractive, abstractive 是传统的两种方式
尽管abstractive更加灵活，但是仍然存在不足：
1.存在unfaithful的摘要，摘要存在着事实性的错误
2.很难控制summary的内容，难以控制摘要生成是哪些方面
因此GSum中可以有不同类型的guidance signals
1.约束摘要的生成，来使输出的内容不要偏离原始文档太多。
2.通过提供不同的输入增加系统的可控制性。
使用`oracle`这种framework来选择包含信息更多的guidance
(1) highlighted sentences in the source document, 
(2) keywords, 
(3) salient relational triples in the form of (subject, relation, object), and 
(4) retrieved summaries.

## Encoder
有两个encoder组成，每一个有$N_{enc}+1$层，每一层是一个SelfAttention和FF层：
LN denotes layer normalization
x = LN(x + SELFATTN(x)),
x = LN(x + FEED FORWARD(x)),
两个encoder会share底层(除了最高一层)的参数，两个原因
1.减少计算和内存的需要。
2.source document和guidance signals之间的区别应该是更高维度的，因此通过编码器的顶层进行捕捉。

## Decoder
共有一个$N_{dec}$层的decoder，每一层由四个组成
经过self-attention模块后，整合guidance signals并生成相应的表示，同时在此基础上整合source document的信息，最后到FF
y = LN(y + SELFATTN(y)),
y = LN(y + CROSS ATTN(y, g)),
y = LN(y + CROSS ATTN(y, x)),
y = LN(y + FEED FORWARD(y)).

## Guidance signals
有两种定义guidance signal的方法：
手动定义用户定义guidance signal g
自动预测：通过自动化的系统推测g
训练过程中，手动提取过于费劲，因此用这两种方法预测
automatic prediction: 像上面描述一样自动预测。
oracle extraction: 在Oracle提取中，我们同时使用x和y来推断一个值g，这个值在生成y时最有可能有用。
理论中automatic prediction有更大的优势，但实验中oracle extraction却有更好的效果

下面是四种guided signals
### Highlighted Sentences.
Extractive的方法教会我们从所有句子的集合中中提取子集。
先用oracle extraction提取出最高ROUGE的句子，作为guidance g
测试时利用预训练的extractive summarization模型，来做automatic prediction.

### Keywords
先用上面提到的贪心方法提取出input sentences
再用TextRank来提取出关键词
利用BertAbs来做automatic prediction


### Relations
用三元组的形式来存储(subject, a relation, and an object)
e.g.Barack Obama was born in Hawaii will create a triple (Barack Obama, was born in, Hawaii).
Stanford OpenIE (Angeli et al., 2015) to extract relational triples from the source document.
利用BertAbs来做automatic prediction

### Retrieved Summaries.
Gold summaries

Elastic search

# Others
- Cross attention: Q!=K=V, Q!=K!=V
- self attention: Q=K=V=X，attention(Q, K, V)=attention(X, X, X)
