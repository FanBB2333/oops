# 以前看过的
1.Chen, Jiaao, 和Diyi Yang. 2021. 《Structure-Aware Abstractive Conversation Summarization via Discourse and Action Graphs》. arXiv:2104.08400 [cs]. http://arxiv.org/abs/2104.08400 (2021年12月3日).

2.Dou, Zi-Yi等. 2021. 《GSum: A General Framework for Guided Neural Abstractive Summarization》. 收入 Proceedings of the 2021 Conference of the North 
American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online: Association for Computational Linguistics, 4830–42. 
https://aclanthology.org/2021.naacl-main.384 (2021年12月18日).

3.Feng, Xiachong, Xiaocheng Feng和Bing Qin. 2021. 《A Survey on Dialogue Summarization: Recent Advances and New Frontiers》. arXiv:2107.03175 [cs]. http://
arxiv.org/abs/2107.03175 (2021年12月3日).

4.Gliwa, Bogdan, Iwona Mochol, Maciej Biesek和Aleksander Wawer. 2019. 《SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization》. 
Proceedings of the 2nd Workshop on New Frontiers in Summarization: 70–79.

5.He, Junxian等. 2020. 《CTRLsum: Towards Generic Controllable Text Summarization》. arXiv:2012.04281 [cs]. http://arxiv.org/abs/2012.04281 (2021年12月17日).

6.Koay, Jia Jin, Alexander Roustai, Xiaojin Dai和Fei Liu. 2021. 《A Sliding-Window Approach to Automatic Creation of Meeting Minutes》. 收入 Proceedings of 
the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop, Online: Association for 
Computational Linguistics, 68–75. https://www.aclweb.org/anthology/2021.naacl-srw.10 (2021年12月6日).

7.Lewis, Mike等. 2019. 《BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension》. arXiv:1910.
13461 [cs, stat]. http://arxiv.org/abs/1910.13461 (2021年12月3日).

8.Liu, Yang, 和Mirella Lapata. 2019. 《Text Summarization with Pretrained Encoders》. arXiv:1908.08345 [cs]. http://arxiv.org/abs/1908.08345 (2021年12月19日).

9.Liu, Zhengyuan, 和Nancy F. Chen. 2021. 《Controllable Neural Dialogue Summarization with Personal Named Entity Planning》. arXiv:2109.13070 [cs]. http://
arxiv.org/abs/2109.13070 (2021年12月3日).

10.Yang, Diyi, 和Lucie Flek. 2021. 《Towards User-Centric Text-to-Text Generation: A Survey》. 收入 Text, Speech, and Dialogue, Lecture Notes in Computer 
Science, 编 Kamil Ekštein, František Pártl和Miloslav Konopík. Cham: Springer International Publishing, 3–22. https://link.springer.com/10.1007/
978-3-030-83527-9_1 (2021年12月15日).

11.Zhong, Ming等. 2020. 《Extractive Summarization as Text Matching》. arXiv:2004.08795 [cs]. http://arxiv.org/abs/2004.08795 (2021年12月19日).

# Others
## SABART的reference

12.A Survey on Dialogue Summarization: Recent Advances and New Frontiers https://arxiv.org/abs/2107.03175

An Exploratory Study on Long Dialogue Summarization: What Works and What's Next https://arxiv.org/abs/2109.04609

13.Summ^ N: A Multi-Stage Summarization Framework for Long Input Dialogues and Documents https://arxiv.org/abs/2110.10150

14.A Finer-grain Universal Dialogue Semantic Structures based Model For Abstractive Dialogue Summarization https://aclanthology.org/2021.findings-emnlp.117/

15.Simple Conversational Data Augmentation for Semi-supervised Abstractive Dialogue Summarization https://aclanthology.org/2021.emnlp-main.530/

16.Capturing Speaker Incorrectness: Speaker-Focused Post-Correction for Abstractive Dialogue Summarization https://aclanthology.org/2021.newsum-1.8/

17.Give the Truth: Incorporate Semantic Slot into Abstractive Dialogue Summarization https://aclanthology.org/2021.findings-emnlp.209/

18.TODSum: Task-Oriented Dialogue Summarization with State Tracking https://arxiv.org/abs/2110.12680

## 递归下去的reference 中 有可能有用的部分

19.Exploring Neural Models for Query-Focused Summarization https://arxiv.org/abs/2112.07637
